#!/usr/bin/env python3
# SPDX-FileCopyrightText: 2024 Jonah Br√ºchert <jbb@kaidan.im>
#
# SPDX-License-Identifier: AGPL-3.0-or-later

import argparse
import json
import metadata
import os
import shutil
import sys
import transitland
import mobilitydatabase

from ruamel.yaml import YAML
from typing import Any
from pathlib import Path
from utils import eprint
from urllib.parse import quote

FEED_PROXY="https://rt.triptix.tech"

def find_motis_asset(asset_name: str):
    motis_path = shutil.which("motis")
    if not motis_path:
        return None
    asset_path = os.path.abspath(os.path.join(motis_path, "..", asset_name))
    return asset_path if os.path.exists(asset_path) else None

def check_file_exist_in_out_folder(file_name: str):
    return os.path.isfile(os.path.join("out", file_name))

def to_motis_rt_spec(spec: str) -> str:
    match spec:
        case 'gtfs-rt': return 'gtfsrt'
        case 'siri-json': return 'siri_json'
    return spec

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Transitous MOTIS configuration generator.')
    parser.add_argument('--import-only', action='store_true', help='Generate configuration for importing only.')
    parser.add_argument('--skip-missing-files', action='store_true', help='Do not generate entry for missing GTFS files')
    parser.add_argument('--feed-proxy', action='store_true', help='Generate configuration for the feed proxy.')
    parser.add_argument('regions', type=str, help='Only generate configuration for the given region(s) (leave empty for all regions, globs are supported)', nargs="*")
    arguments = parser.parse_args()

    feed_dir = Path("feeds/")
    script_dir = Path("scripts/")

    atlas = transitland.Atlas.load(Path("transitland-atlas/"))
    mdb = mobilitydatabase.Database.load()

    gtfs_feeds: list[dict] = []
    gtfsrt_feeds: list[dict] = []

    with open("motis/config.yml") as f:
        yaml = YAML(typ="rt")

        config = yaml.load(f)
        config.yaml_set_comment_before_after_key(
            "server",
            before="This file is automatically generated by ./src/generate-motis-config.py from motis/config.yml",
        )

        web_folder = find_motis_asset("ui/")
        if web_folder:
            config["server"]["web_folder"] = web_folder

        if arguments.import_only:
            config.pop("tiles")
        else:
            tile_profile = find_motis_asset("tiles-profiles/full.lua")
            if tile_profile:
                config["tiles"]["profile"] = tile_profile

        config["timetable"].yaml_set_comment_before_after_key(
            "datasets", before="Modified by generate-motis-config.py"
        )
        config["timetable"]["datasets"] = {}
        config["gbfs"]["feeds"] = {}
        config["gbfs"]["proxy"] = FEED_PROXY

        # TODO backward compatibility, remove this in a few months
        while "full" in arguments.regions:
            print("Ignoring legacy option 'full', this is the default now.")
            arguments.regions.remove("full")

        feeds = []
        if len(arguments.regions) == 0:
            feeds = feed_dir.glob("*.json")
        else:
            for region in arguments.regions:
                feeds += feed_dir.glob(f"{region}.json")

        ignored_feeds = set() # for feeds ignored due to missing file

        for feed in sorted(feeds):
            with open(feed, "r") as f:
                parsed = json.load(f)
                region = metadata.Region(parsed)

                metadata_filename = feed.name
                region_name = metadata_filename[: metadata_filename.rfind(".")]

                for source in region.sources:
                    schedule_name = f"{region_name}-{source.name}"

                    if source.skip:
                        continue

                    resolved_sources = []
                    match source:
                        case metadata.TransitlandSource():
                            resolved_sources = atlas.sources_by_id(source)
                            if not resolved_sources:
                                eprint("Error: Could not resolve", source.transitland_atlas_id)
                                sys.exit(1)
                        case metadata.MobilityDatabaseSource():
                            resolved_source = mdb.source_by_id(source)
                            if not resolved_source:
                                eprint("Error: Could not resolve", source.mdb_id)
                                sys.exit(1)
                            resolved_sources = [resolved_source]
                        case _:
                            resolved_sources = [source]

                    for source in resolved_sources:
                        use_original_url = isinstance(source, metadata.UrlSource) and not source.use_feed_proxy
                        if arguments.feed_proxy and use_original_url and source.spec != "gbfs":
                            continue
                        if arguments.feed_proxy:
                            use_original_url = True
                        match source.spec:
                            case source.spec if source.spec in ["gtfs", "netex"]:
                                schedule_file = \
                                    f"{region_name}_{source.name}.{source.spec}.zip"
                                name = f"{region_name}-{source.name}"
                                if (not arguments.skip_missing_files) or check_file_exist_in_out_folder(schedule_file):
                                    config["timetable"]["datasets"][name] = \
                                        {
                                            "path": schedule_file,
                                            "extend_calendar": source.extend_calendar
                                        }
                                    if source.default_timezone is not None:
                                        config["timetable"]["datasets"][name]["default_timezone"] = source.default_timezone

                                    if source.script is not None:
                                        if not os.path.exists(os.path.join(script_dir, source.script)):
                                            eprint(f"Error: Import script {source.script} for {name} could not be found.")
                                            sys.exit(1)
                                        config["timetable"]["datasets"][name]["script"] = f"scripts/{source.script}"
                                else:
                                    print("Warning: Skipping " + name + " as " + schedule_file + " is missing.")
                                    ignored_feeds.add(name)

                            case source.spec if isinstance(source, metadata.UrlSource) and source.spec in ["gtfs-rt", "siri", "siri-json"]:
                                name = f"{region_name}-{source.name}"
                                if name not in config["timetable"]["datasets"]:
                                    eprint(
                                        "Error: The name of a realtime (gtfs-rt) "
                                        + "feed needs to match the name of its "
                                        + "static base feed defined before the "
                                        + "realtime feed. Found nothing "
                                        + "belonging to",
                                        source.name,
                                    )
                                    sys.exit(1)

                                if "rt" not in config["timetable"]["datasets"][name]:
                                    config["timetable"]["datasets"][name]["rt"] = []

                                rt_feed: dict[str, Any] = {
                                    "url": source.url if use_original_url else FEED_PROXY + '/feed/' + quote(name) + "-" + str(len(config["timetable"]["datasets"][name]["rt"])),
                                    "protocol": to_motis_rt_spec(source.spec)
                                }

                                if source.headers and use_original_url:
                                    rt_feed["headers"] = source.headers

                                config["timetable"]["datasets"][name]["rt"] \
                                        .append(rt_feed)

                            case "gbfs" if isinstance(source, metadata.UrlSource):
                                name = f"{region_name}-{source.name}"
                                config["gbfs"]["feeds"][name] = {"url": source.url if use_original_url else FEED_PROXY + '/feed/' + quote(name)}
                                if source.headers and use_original_url:
                                    config["gbfs"]["feeds"][name]["headers"] = source.headers

        if arguments.feed_proxy:
            with open("/tmp/feed-proxy-vars.yml", "w") as fo:
                feed_vars = {}
                for key in config["timetable"]["datasets"]:
                    if not "rt" in config["timetable"]["datasets"][key]:
                        continue
                    for i, rt_feed in enumerate(config["timetable"]["datasets"][key]["rt"]):
                        feed_vars[key + '-' + str(i)] = rt_feed
                for key in config["gbfs"]["feeds"]:
                    feed_vars[key] = config["gbfs"]["feeds"][key]
                    feed_vars[key]['gbfs'] = True
                yaml.dump(feed_vars, fo)    
        else:
            with open("out/config.yml", "w") as fo:
                yaml.dump(config, fo)

    # copy scripts
    shutil.rmtree("out/scripts", ignore_errors=True)
    shutil.copytree(script_dir, "out/scripts")
